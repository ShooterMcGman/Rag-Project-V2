{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4108bcc-d7ab-4e87-bc8e-e905da89876a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully updated: src/detection/config.py\n",
      "‚úÖ Successfully updated: src/detection/exceptions.py\n",
      "‚úÖ Successfully updated: src/detection/utils.py\n",
      "‚úÖ Successfully updated: src/detection/detect_toc.py\n",
      "‚úÖ Successfully updated: src/utils/git_utils.py\n",
      "\n",
      "üéâ All specified files have been updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the project root directory\n",
    "project_root = os.getcwd()  # Ensure the Jupyter Notebook is running in the project root\n",
    "\n",
    "# Function to write content to a file\n",
    "def write_file(relative_path, content):\n",
    "    \"\"\"\n",
    "    Writes the given content to the file at the relative path.\n",
    "    \n",
    "    Args:\n",
    "        relative_path (str): Relative path to the file from the project root.\n",
    "        content (str): Content to write into the file.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\"‚úÖ Successfully updated: {relative_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to update {relative_path}: {e}\")\n",
    "\n",
    "# 1. Update src/detection/config.py\n",
    "config_py_content = '''\\\n",
    "# src/detection/config.py\n",
    "\n",
    "import os\n",
    "\n",
    "# Project Root Directory\n",
    "CURRENT_FILE = os.path.abspath(__file__)\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(CURRENT_FILE), \"../../\"))\n",
    "\n",
    "# Data Directories\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, \"raw_data\")\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, \"processed_data\")\n",
    "SAMPLE_DOCUMENTS_DIR = os.path.join(DATA_DIR, \"sample_documents\")\n",
    "\n",
    "# Logs Configuration\n",
    "LOG_DIR = os.path.join(PROJECT_ROOT, \"logs\")\n",
    "DETECTION_LOG_FILE = os.path.join(LOG_DIR, \"detection_errors.log\")\n",
    "PERFORMANCE_LOG_FILE = os.path.join(LOG_DIR, \"performance_logs\", \"performance_metrics.log\")\n",
    "\n",
    "# Supported File Formats\n",
    "SUPPORTED_FORMATS = (\".pdf\", \".docx\")\n",
    "\n",
    "# TOC Detection Regex Patterns\n",
    "PDF_TOC_REGEX = r\"\\\\d+(\\\\.\\\\d+)*\\\\s+[\\\\w\\\\s]+(\\\\.\\\\.\\\\.\\\\d+)?\"\n",
    "DOCX_TOC_REGEX = r\"\\\\d+(\\\\.\\\\d+)*\\\\s+[\\\\w\\\\s]+(\\\\.\\\\.\\\\.\\\\d+)?\"\n",
    "\n",
    "# Logging Settings\n",
    "LOGGING_LEVEL = \"INFO\"\n",
    "LOGGING_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "\n",
    "# Git Commit Message\n",
    "GIT_COMMIT_MESSAGE = \"Processed multiple sample files for TOC detection\"\n",
    "'''\n",
    "write_file('src/detection/config.py', config_py_content)\n",
    "\n",
    "# 2. Update src/detection/exceptions.py\n",
    "exceptions_py_content = '''\\\n",
    "# src/detection/exceptions.py\n",
    "\n",
    "class TOCDetectionError(Exception):\n",
    "    \"\"\"Base exception for TOC detection errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class UnsupportedFileFormatError(TOCDetectionError):\n",
    "    \"\"\"Exception raised for unsupported file formats.\"\"\"\n",
    "    pass\n",
    "\n",
    "class FileProcessingError(TOCDetectionError):\n",
    "    \"\"\"Exception raised when file processing fails.\"\"\"\n",
    "    pass\n",
    "'''\n",
    "write_file('src/detection/exceptions.py', exceptions_py_content)\n",
    "\n",
    "# 3. Update src/detection/utils.py\n",
    "detection_utils_py_content = '''\\\n",
    "# src/detection/utils.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from .config import LOG_DIR, DETECTION_LOG_FILE, LOGGING_LEVEL, LOGGING_FORMAT\n",
    "from .exceptions import UnsupportedFileFormatError\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"\n",
    "    Sets up logging with both file and console handlers.\n",
    "    Ensures that the log directory exists.\n",
    "    \"\"\"\n",
    "    os.makedirs(LOG_DIR, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(DETECTION_LOG_FILE), exist_ok=True)\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(getattr(logging, LOGGING_LEVEL.upper(), logging.INFO))\n",
    "    \n",
    "    # File Handler\n",
    "    file_handler = logging.FileHandler(DETECTION_LOG_FILE)\n",
    "    file_formatter = logging.Formatter(LOGGING_FORMAT)\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    # Console Handler\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_formatter = logging.Formatter(LOGGING_FORMAT)\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "def validate_file_path(file_path, supported_formats):\n",
    "    \"\"\"\n",
    "    Validates if the file exists and is of a supported format.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the file.\n",
    "        supported_formats (tuple): Supported file extensions.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "        UnsupportedFileFormatError: If the file format is unsupported.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    if not file_path.lower().endswith(supported_formats):\n",
    "        raise UnsupportedFileFormatError(f\"Unsupported file format: {file_path}\")\n",
    "'''\n",
    "write_file('src/detection/utils.py', detection_utils_py_content)\n",
    "\n",
    "# 4. Update src/detection/detect_toc.py\n",
    "detect_toc_py_content = '''\\\n",
    "# src/detection/detect_toc.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "from .config import (\n",
    "    PROJECT_ROOT,\n",
    "    SUPPORTED_FORMATS,\n",
    "    PDF_TOC_REGEX,\n",
    "    DOCX_TOC_REGEX\n",
    ")\n",
    "from .exceptions import (\n",
    "    TOCDetectionError,\n",
    "    UnsupportedFileFormatError,\n",
    "    FileProcessingError\n",
    ")\n",
    "from .utils import validate_file_path\n",
    "\n",
    "def detect_toc(file_path):\n",
    "    \"\"\"\n",
    "    Detects a Table of Contents (TOC) in a document.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the document.\n",
    "\n",
    "    Returns:\n",
    "        dict: Detected TOC structure and metadata.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Starting TOC detection for file: {file_path}\")\n",
    "    try:\n",
    "        validate_file_path(file_path, SUPPORTED_FORMATS)\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        if ext == \".pdf\":\n",
    "            result = detect_toc_pdf(file_path)\n",
    "        elif ext == \".docx\":\n",
    "            result = detect_toc_docx(file_path)\n",
    "        else:\n",
    "            raise UnsupportedFileFormatError(\"Only PDF and DOCX formats are supported.\")\n",
    "        logging.info(f\"TOC detection completed successfully for {file_path}\")\n",
    "        return result\n",
    "    except TOCDetectionError as e:\n",
    "        logging.error(f\"TOCDetectionError: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error during TOC detection for {file_path}: {e}\")\n",
    "        raise FileProcessingError(f\"Failed to process {file_path}\") from e\n",
    "\n",
    "def detect_toc_pdf(file_path):\n",
    "    \"\"\"Detects TOC patterns in a PDF file.\"\"\"\n",
    "    toc_structure = []\n",
    "    try:\n",
    "        reader = PdfReader(file_path)\n",
    "        for page_number, page in enumerate(reader.pages, start=1):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                matches = re.findall(PDF_TOC_REGEX, text)\n",
    "                # Flatten the matches if regex has groups\n",
    "                flat_matches = [\".\".join(filter(None, match)).strip() for match in matches]\n",
    "                toc_structure.extend(flat_matches)\n",
    "            else:\n",
    "                logging.warning(f\"No text found on page {page_number} of {file_path}\")\n",
    "        return {\"format\": \"PDF\", \"toc_structure\": toc_structure}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing PDF file {file_path}: {e}\")\n",
    "        raise FileProcessingError(f\"Error processing PDF file {file_path}\") from e\n",
    "\n",
    "def detect_toc_docx(file_path):\n",
    "    \"\"\"Detects TOC patterns in a DOCX file.\"\"\"\n",
    "    toc_structure = []\n",
    "    try:\n",
    "        doc = Document(file_path)\n",
    "        for para_number, paragraph in enumerate(doc.paragraphs, start=1):\n",
    "            matches = re.findall(DOCX_TOC_REGEX, paragraph.text)\n",
    "            flat_matches = [\".\".join(filter(None, match)).strip() for match in matches]\n",
    "            toc_structure.extend(flat_matches)\n",
    "        return {\"format\": \"DOCX\", \"toc_structure\": toc_structure}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing DOCX file {file_path}: {e}\")\n",
    "        raise FileProcessingError(f\"Error processing DOCX file {file_path}\") from e\n",
    "'''\n",
    "write_file('src/detection/detect_toc.py', detect_toc_py_content)\n",
    "\n",
    "# 5. Update src/utils/git_utils.py\n",
    "git_utils_py_content = '''\\\n",
    "# src/utils/git_utils.py\n",
    "\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "def auto_commit_push(commit_message):\n",
    "    \"\"\"\n",
    "    Automatically commits and pushes changes to the Git repository.\n",
    "\n",
    "    Args:\n",
    "        commit_message (str): The commit message.\n",
    "\n",
    "    Raises:\n",
    "        subprocess.CalledProcessError: If Git commands fail.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logging.info(\"Staging changes for commit...\")\n",
    "        subprocess.run([\"git\", \"add\", \".\"], check=True)\n",
    "        \n",
    "        logging.info(\"Committing changes...\")\n",
    "        subprocess.run([\"git\", \"commit\", \"-m\", commit_message], check=True)\n",
    "        \n",
    "        logging.info(\"Pushing to remote repository...\")\n",
    "        subprocess.run([\"git\", \"push\"], check=True)\n",
    "        \n",
    "        logging.info(\"Git commit and push completed successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        logging.error(f\"Git command failed: {e}\")\n",
    "        raise\n",
    "'''\n",
    "write_file('src/utils/git_utils.py', git_utils_py_content)\n",
    "\n",
    "print(\"\\nüéâ All specified files have been updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a58b4-2874-46bd-bf8e-0518779ab0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae27fd-d67a-4559-8ec3-ca2f7fc58718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (toc_project)",
   "language": "python",
   "name": "toc_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
